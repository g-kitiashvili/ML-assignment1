{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Prices â€“ Model Inference\n",
    "\n",
    "Test Set Prediction using the Best Model from Model Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T13:07:50.744435Z",
     "start_time": "2025-06-24T13:07:48.634305Z"
    }
   },
   "source": [
    "%pip install -q dagshub mlflow\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.environ['MLFLOW_TRACKING_URI'] = 'https://dagshub.com/g-kitiashvili/ML-assignment1.mlflow'\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = 'g-kitiashvili'\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = '1c2227158cc19daf66bb3b241116a8e8c5f1cd20'\n",
    "\n",
    "print(\"House Prices - Model Inference\")\n",
    "print(\"=\" * 50)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "House Prices - Model Inference\n",
      "==================================================\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Test Data and Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T13:07:50.919880Z",
     "start_time": "2025-06-24T13:07:50.858572Z"
    }
   },
   "source": [
    "# Load test data\n",
    "test_data = pd.read_csv('house-prices-advanced-regression-techniques/test.csv')\n",
    "test_ids = test_data['Id'].copy()\n",
    "\n",
    "print(f\"Test data shape: {test_data.shape}\")\n",
    "\n",
    "# Define the same preprocessing functions from experiment notebook\n",
    "def clean_data(df, is_train=True):\n",
    "    \"\"\"\n",
    "    Data cleaning function (same as in experiment)\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Remove outliers (only for training data)\n",
    "    if is_train:\n",
    "        # Remove extreme outliers based on GrLivArea and SalePrice\n",
    "        df_clean = df_clean.drop(df_clean[(df_clean['GrLivArea'] > 4000) & \n",
    "                                         (df_clean['SalePrice'] < 300000)].index)\n",
    "    \n",
    "    # Handle missing values for specific features\n",
    "    # Categorical features with meaningful NA\n",
    "    categorical_na_features = ['Alley', 'BsmtQual', 'BsmtCond', 'BsmtExposure', \n",
    "                              'BsmtFinType1', 'BsmtFinType2', 'FireplaceQu',\n",
    "                              'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
    "                              'PoolQC', 'Fence', 'MiscFeature']\n",
    "    \n",
    "    for feature in categorical_na_features:\n",
    "        if feature in df_clean.columns:\n",
    "            df_clean[feature] = df_clean[feature].fillna('None')\n",
    "    \n",
    "    # Numerical features with meaningful zero\n",
    "    numerical_zero_features = ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n",
    "                              'BsmtFullBath', 'BsmtHalfBath', 'GarageYrBlt',\n",
    "                              'GarageArea', 'GarageCars', 'MasVnrArea']\n",
    "    \n",
    "    for feature in numerical_zero_features:\n",
    "        if feature in df_clean.columns:\n",
    "            df_clean[feature] = df_clean[feature].fillna(0)\n",
    "    \n",
    "    # Other categorical features - fill with mode\n",
    "    categorical_features = df_clean.select_dtypes(include=['object']).columns\n",
    "    for feature in categorical_features:\n",
    "        if df_clean[feature].isnull().any():\n",
    "            mode_value = df_clean[feature].mode()[0] if len(df_clean[feature].mode()) > 0 else 'Unknown'\n",
    "            df_clean[feature] = df_clean[feature].fillna(mode_value)\n",
    "    \n",
    "    # Numerical features - fill with median\n",
    "    numerical_features = df_clean.select_dtypes(include=[np.number]).columns\n",
    "    for feature in numerical_features:\n",
    "        if df_clean[feature].isnull().any():\n",
    "            median_value = df_clean[feature].median()\n",
    "            df_clean[feature] = df_clean[feature].fillna(median_value)\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "def feature_engineering(df):\n",
    "    \"\"\"\n",
    "    Feature engineering function (same as in experiment)\n",
    "    \"\"\"\n",
    "    df_fe = df.copy()\n",
    "    \n",
    "    # Create new features\n",
    "    df_fe['TotalSF'] = df_fe['TotalBsmtSF'] + df_fe['1stFlrSF'] + df_fe['2ndFlrSF']\n",
    "    df_fe['Total_Bathrooms'] = (df_fe['FullBath'] + (0.5 * df_fe['HalfBath']) +\n",
    "                               df_fe['BsmtFullBath'] + (0.5 * df_fe['BsmtHalfBath']))\n",
    "    df_fe['Total_porch_sf'] = (df_fe['OpenPorchSF'] + df_fe['3SsnPorch'] +\n",
    "                              df_fe['EnclosedPorch'] + df_fe['ScreenPorch'] +\n",
    "                              df_fe['WoodDeckSF'])\n",
    "    \n",
    "    # Age of house\n",
    "    df_fe['HouseAge'] = df_fe['YrSold'] - df_fe['YearBuilt']\n",
    "    df_fe['RemodAge'] = df_fe['YrSold'] - df_fe['YearRemodAdd']\n",
    "    \n",
    "    # Garage age\n",
    "    df_fe['GarageAge'] = df_fe['YrSold'] - df_fe['GarageYrBlt']\n",
    "    df_fe['GarageAge'] = df_fe['GarageAge'].fillna(0)\n",
    "    \n",
    "    # Has features\n",
    "    df_fe['HasBasement'] = (df_fe['TotalBsmtSF'] > 0).astype(int)\n",
    "    df_fe['HasGarage'] = (df_fe['GarageArea'] > 0).astype(int)\n",
    "    df_fe['HasFireplace'] = (df_fe['Fireplaces'] > 0).astype(int)\n",
    "    df_fe['HasPool'] = (df_fe['PoolArea'] > 0).astype(int)\n",
    "    \n",
    "    # Price per square foot proxies\n",
    "    df_fe['Price_per_sqft_total'] = df_fe['TotalSF']\n",
    "    df_fe['Price_per_sqft_living'] = df_fe['GrLivArea']\n",
    "    \n",
    "    return df_fe"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: (1459, 80)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Best Model from MLflow"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T13:08:01.527579Z",
     "start_time": "2025-06-24T13:07:50.975951Z"
    }
   },
   "source": [
    "print(\"Loading best model and preprocessing artifacts from MLflow...\")\n",
    "\n",
    "try:\n",
    "    # Load latest version of the registered model\n",
    "    model_name = \"house_prices_final_model\"\n",
    "    model_version = \"latest\"\n",
    "    \n",
    "    model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "    model = mlflow.sklearn.load_model(model_uri)\n",
    "    \n",
    "    print(f\"Successfully loaded model: {model_name}\")\n",
    "    print(f\"Model type: {type(model)}\")\n",
    "    \n",
    "    # Get the run ID to load preprocessing artifacts\n",
    "    client = MlflowClient()\n",
    "    model_version_info = client.get_model_version(model_name, model_version)\n",
    "    run_id = model_version_info.run_id\n",
    "    \n",
    "    print(f\"Model run ID: {run_id}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading model from registry: {e}\")\n",
    "    print(\"Attempting to load from latest run...\")\n",
    "    \n",
    "    # Fallback: load from latest experiment run\n",
    "    experiment = mlflow.get_experiment_by_name(\"house-prices-experiments\")\n",
    "    runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "    \n",
    "    # Find the run with final model registration\n",
    "    final_run = None\n",
    "    for _, run in runs.iterrows():\n",
    "        if run['tags.mlflow.runName'] == 'Final_Model_Registration':\n",
    "            final_run = run\n",
    "            break\n",
    "    \n",
    "    if final_run is None:\n",
    "        final_run = runs.iloc[0]  # Use latest run as fallback\n",
    "    \n",
    "    run_id = final_run.run_id\n",
    "    model_uri = f\"runs:/{run_id}/final_model\"\n",
    "    model = mlflow.sklearn.load_model(model_uri)\n",
    "    print(f\"Successfully loaded model from run: {run_id}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best model and preprocessing artifacts from MLflow...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model: house_prices_final_model\n",
      "Model type: <class 'sklearn.linear_model._coordinate_descent.Lasso'>\n",
      "Error loading model from registry: INVALID_PARAMETER_VALUE: Response: {'error_code': 'INVALID_PARAMETER_VALUE'}\n",
      "Attempting to load from latest run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model from run: ed7c4e51921249dd84d77527ab25578f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Recreate Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T13:08:01.621437Z",
     "start_time": "2025-06-24T13:08:01.540585Z"
    }
   },
   "source": [
    "print(\"Recreating preprocessing pipeline...\")\n",
    "\n",
    "# Load training data to recreate the exact preprocessing pipeline\n",
    "train_data = pd.read_csv('house-prices-advanced-regression-techniques/train.csv')\n",
    "\n",
    "# Apply same preprocessing steps as training\n",
    "train_clean = clean_data(train_data, is_train=True)\n",
    "test_clean = clean_data(test_data, is_train=False)\n",
    "\n",
    "train_fe = feature_engineering(train_clean)\n",
    "test_fe = feature_engineering(test_clean)\n",
    "\n",
    "print(f\"Train data shape after feature engineering: {train_fe.shape}\")\n",
    "print(f\"Test data shape after feature engineering: {test_fe.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recreating preprocessing pipeline...\n",
      "Train data shape after feature engineering: (1458, 93)\n",
      "Test data shape after feature engineering: (1459, 92)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T13:08:01.750778Z",
     "start_time": "2025-06-24T13:08:01.679799Z"
    }
   },
   "source": [
    "def encode_features(train_df, test_df, target_col='SalePrice'):\n",
    "    \"\"\"\n",
    "    Encode categorical features (exact same function as training)\n",
    "    \"\"\"\n",
    "    # Separate features and target\n",
    "    if target_col in train_df.columns:\n",
    "        X_train = train_df.drop(columns=[target_col])\n",
    "        y_train = train_df[target_col]\n",
    "    else:\n",
    "        X_train = train_df.copy()\n",
    "        y_train = None\n",
    "    \n",
    "    X_test = test_df.copy()\n",
    "    \n",
    "    # Get categorical and numerical features\n",
    "    categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "    numerical_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    # Remove ID column if present\n",
    "    if 'Id' in numerical_features:\n",
    "        numerical_features.remove('Id')\n",
    "        X_train = X_train.drop('Id', axis=1)\n",
    "        X_test = X_test.drop('Id', axis=1)\n",
    "    \n",
    "    # One-hot encoding for categorical features\n",
    "    X_train_encoded = pd.get_dummies(X_train, columns=categorical_features, drop_first=True)\n",
    "    X_test_encoded = pd.get_dummies(X_test, columns=categorical_features, drop_first=True)\n",
    "    \n",
    "    # Align columns between train and test\n",
    "    missing_cols_test = set(X_train_encoded.columns) - set(X_test_encoded.columns)\n",
    "    missing_cols_train = set(X_test_encoded.columns) - set(X_train_encoded.columns)\n",
    "    \n",
    "    # Add missing columns to test set\n",
    "    for col in missing_cols_test:\n",
    "        X_test_encoded[col] = 0\n",
    "    \n",
    "    # Add missing columns to train set\n",
    "    for col in missing_cols_train:\n",
    "        X_train_encoded[col] = 0\n",
    "    \n",
    "    # Reorder columns\n",
    "    X_test_encoded = X_test_encoded[X_train_encoded.columns]\n",
    "    \n",
    "    return X_train_encoded, X_test_encoded, y_train\n",
    "\n",
    "X_train_encoded, X_test_encoded, y_train = encode_features(train_fe, test_fe)\n",
    "print(f\"Encoded training features shape: {X_train_encoded.shape}\")\n",
    "print(f\"Encoded test features shape: {X_test_encoded.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded training features shape: (1458, 269)\n",
      "Encoded test features shape: (1459, 269)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Selection & Prediction"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T13:08:02.623809Z",
     "start_time": "2025-06-24T13:08:01.815256Z"
    }
   },
   "source": [
    "print(\"Recreating feature selection...\")\n",
    "\n",
    "# We need to recreate the feature selection based on the best method found in training\n",
    "# From the training script, we need to determine which method was used\n",
    "\n",
    "# Import required modules for feature selection\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, RFE, SelectFromModel\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Try to load feature selection info from run parameters\n",
    "try:\n",
    "    run = mlflow.get_run(run_id)\n",
    "    \n",
    "    # Check if we can get the feature selection method from parameters\n",
    "    feature_selection_method = None\n",
    "    for param_key, param_value in run.data.params.items():\n",
    "        if 'feature_selection' in param_key.lower():\n",
    "            feature_selection_method = param_value\n",
    "            break\n",
    "    \n",
    "    if feature_selection_method is None:\n",
    "        # Default to trying all methods and picking the one that gives the right number of features\n",
    "        print(\"Feature selection method not found in parameters, recreating...\")\n",
    "        \n",
    "        # Try different feature selection methods to match the expected number of features\n",
    "        methods_to_try = ['univariate', 'rfe', 'lasso']\n",
    "        \n",
    "        for method in methods_to_try:\n",
    "            if method == 'univariate':\n",
    "                selector = SelectKBest(score_func=f_regression, k=50)\n",
    "            elif method == 'rfe':\n",
    "                estimator = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "                selector = RFE(estimator, n_features_to_select=50)\n",
    "            elif method == 'lasso':\n",
    "                lasso = Lasso(alpha=0.01, random_state=42)\n",
    "                selector = SelectFromModel(lasso)\n",
    "            \n",
    "            # Fit on training data\n",
    "            X_train_selected = selector.fit_transform(X_train_encoded, y_train)\n",
    "            \n",
    "            print(f\"Method {method}: {X_train_selected.shape[1]} features selected\")\n",
    "            \n",
    "            # Check if this matches our model's expected input\n",
    "            if X_train_selected.shape[1] == 268:  # Expected number from error message\n",
    "                feature_selection_method = method\n",
    "                print(f\"Found matching method: {method}\")\n",
    "                break\n",
    "        \n",
    "        if feature_selection_method is None:\n",
    "            # If still not found, try with different k values for SelectKBest\n",
    "            for k in [268, 260, 250, 240]:\n",
    "                selector = SelectKBest(score_func=f_regression, k=k)\n",
    "                X_train_selected = selector.fit_transform(X_train_encoded, y_train)\n",
    "                if X_train_selected.shape[1] == 268:\n",
    "                    feature_selection_method = f'univariate_k{k}'\n",
    "                    print(f\"Found matching method: univariate with k={k}\")\n",
    "                    break\n",
    "    \n",
    "    print(f\"Using feature selection method: {feature_selection_method}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving run info: {e}\")\n",
    "    feature_selection_method = 'univariate'  # Default fallback\n",
    "\n",
    "# Apply the identified feature selection method\n",
    "if 'univariate' in feature_selection_method:\n",
    "    if 'k' in feature_selection_method:\n",
    "        k = int(feature_selection_method.split('k')[1])\n",
    "    else:\n",
    "        k = 268  # Use the expected number directly\n",
    "    selector = SelectKBest(score_func=f_regression, k=k)\n",
    "elif feature_selection_method == 'rfe':\n",
    "    estimator = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "    selector = RFE(estimator, n_features_to_select=268)\n",
    "elif feature_selection_method == 'lasso':\n",
    "    lasso = Lasso(alpha=0.01, random_state=42)\n",
    "    selector = SelectFromModel(lasso)\n",
    "else:\n",
    "    # Default fallback\n",
    "    selector = SelectKBest(score_func=f_regression, k=268)\n",
    "\n",
    "# Fit selector on training data and transform both train and test\n",
    "X_train_selected = selector.fit_transform(X_train_encoded, y_train)\n",
    "X_test_selected = selector.transform(X_test_encoded)\n",
    "\n",
    "print(f\"Selected features shape - Train: {X_train_selected.shape}\")\n",
    "print(f\"Selected features shape - Test: {X_test_selected.shape}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recreating feature selection...\n",
      "Using feature selection method: lasso\n",
      "Selected features shape - Train: (1458, 268)\n",
      "Selected features shape - Test: (1459, 268)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T13:08:12.413553Z",
     "start_time": "2025-06-24T13:08:02.684428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Generating predictions...\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"Test_Predictions_Fixed\") as run:\n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test_selected)\n",
    "    \n",
    "    # Log prediction info\n",
    "    mlflow.log_param(\"test_samples\", len(predictions))\n",
    "    mlflow.log_param(\"features_used\", X_test_selected.shape[1])\n",
    "    mlflow.log_param(\"feature_selection_method\", feature_selection_method)\n",
    "    mlflow.log_metric(\"prediction_mean\", predictions.mean())\n",
    "    mlflow.log_metric(\"prediction_std\", predictions.std())\n",
    "    mlflow.log_metric(\"prediction_min\", predictions.min())\n",
    "    mlflow.log_metric(\"prediction_max\", predictions.max())\n",
    "    \n",
    "    print(f\"Predictions generated for {len(predictions)} samples\")\n",
    "    print(f\"Using {X_test_selected.shape[1]} features\")\n",
    "    print(f\"Prediction statistics:\")\n",
    "    print(f\"  Mean: ${predictions.mean():,.2f}\")\n",
    "    print(f\"  Std:  ${predictions.std():,.2f}\")\n",
    "    print(f\"  Min:  ${predictions.min():,.2f}\")\n",
    "    print(f\"  Max:  ${predictions.max():,.2f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Predictions generated for 1459 samples\n",
      "Using 268 features\n",
      "Prediction statistics:\n",
      "  Mean: $175,398.37\n",
      "  Std:  $79,001.74\n",
      "  Min:  $16,458.88\n",
      "  Max:  $725,429.48\n",
      "ðŸƒ View run Test_Predictions_Fixed at: https://dagshub.com/g-kitiashvili/ML-assignment1.mlflow/#/experiments/0/runs/5693b05d8b1b41efb772b3483a055f0d\n",
      "ðŸ§ª View experiment at: https://dagshub.com/g-kitiashvili/ML-assignment1.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create Submission File"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T13:08:12.499094Z",
     "start_time": "2025-06-24T13:08:12.484788Z"
    }
   },
   "source": [
    "print(\"Creating submission file...\")\n",
    "\n",
    "# Create submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test_ids,\n",
    "    'SalePrice': predictions\n",
    "})\n",
    "\n",
    "# Save submission file\n",
    "submission_filename = 'house_prices_submission.csv'\n",
    "submission.to_csv(submission_filename, index=False)\n",
    "\n",
    "print(f\"Submission file saved as: {submission_filename}\")\n",
    "print(f\"Submission shape: {submission.shape}\")\n",
    "print(\"\\nFirst 10 predictions:\")\n",
    "print(submission.head(10))\n",
    "\n",
    "print(\"\\n=== INFERENCE COMPLETED SUCCESSFULLY ===\")\n",
    "print(f\"Submission file '{submission_filename}' ready for Kaggle upload!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating submission file...\n",
      "Submission file saved as: house_prices_submission.csv\n",
      "Submission shape: (1459, 2)\n",
      "\n",
      "First 10 predictions:\n",
      "     Id      SalePrice\n",
      "0  1461  101462.695518\n",
      "1  1462  152352.762983\n",
      "2  1463  181233.428427\n",
      "3  1464  193084.790770\n",
      "4  1465  198917.694059\n",
      "5  1466  164474.887398\n",
      "6  1467  169928.213979\n",
      "7  1468  151305.291734\n",
      "8  1469  204763.001443\n",
      "9  1470  104635.186381\n",
      "\n",
      "=== INFERENCE COMPLETED SUCCESSFULLY ===\n",
      "Submission file 'house_prices_submission.csv' ready for Kaggle upload!\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T13:08:12.573442Z",
     "start_time": "2025-06-24T13:08:12.569777Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
