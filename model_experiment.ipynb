{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Prices - Advanced Regression Techniques\n",
    "## Model Experiment Notebook\n",
    "\n",
    "This notebook implements a comprehensive machine learning pipeline for the House Prices prediction competition, including:\n",
    "- Data exploration and cleaning\n",
    "- Feature engineering and selection\n",
    "- Model training and evaluation\n",
    "- Hyperparameter optimization\n",
    "- MLflow experiment tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initial Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install -q dagshub mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, RFE, SelectFromModel\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import xgboost as xgb\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow Setup - DagHub connection\n",
    "os.environ['MLFLOW_TRACKING_URI'] = 'https://dagshub.com/g-kitiashvili/ML-assignment1.mlflow'\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = 'g-kitiashvili'\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = '1c2227158cc19daf66bb3b241116a8e8c5f1cd20' \n",
    "mlflow.set_experiment(f\"house-prices-experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data = pd.read_csv('house-prices-advanced-regression-techniques/train.csv')\n",
    "test_data = pd.read_csv('house-prices-advanced-regression-techniques/test.csv')\n",
    "\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info about the data\n",
    "print(\"Training data info:\")\n",
    "print(train_data.info())\n",
    "print(\"\\nTarget variable statistics:\")\n",
    "print(train_data['SalePrice'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start MLflow run for EDA\n",
    "with mlflow.start_run(run_name=\"EDA\"):\n",
    "    # Log dataset info\n",
    "    mlflow.log_param(\"train_shape\", train_data.shape)\n",
    "    mlflow.log_param(\"test_shape\", test_data.shape)\n",
    "    \n",
    "    # Missing values analysis\n",
    "    missing_data = train_data.isnull().sum().sort_values(ascending=False)\n",
    "    missing_percent = (missing_data / len(train_data)) * 100\n",
    "    missing_df = pd.DataFrame({'Missing Count': missing_data, 'Percentage': missing_percent})\n",
    "    missing_df = missing_df[missing_df['Missing Count'] > 0]\n",
    "    \n",
    "    print(\"Missing values:\")\n",
    "    print(missing_df.head(20))\n",
    "    \n",
    "    mlflow.log_metric(\"missing_features_count\", len(missing_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Target variable distribution\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(train_data['SalePrice'], bins=50)\n",
    "    plt.title('SalePrice Distribution')\n",
    "    plt.xlabel('Price')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(np.log(train_data['SalePrice']), bins=50)\n",
    "    plt.title('Log SalePrice Distribution')\n",
    "    plt.xlabel('Log Price')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('target_distribution.png')\n",
    "    mlflow.log_artifact('target_distribution.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Correlation with target\n",
    "    numeric_features = train_data.select_dtypes(include=[np.number]).columns\n",
    "    correlations = train_data[numeric_features].corr()['SalePrice'].sort_values(ascending=False)\n",
    "    print(\"\\nTop correlations with SalePrice:\")\n",
    "    print(correlations.head(15))\n",
    "    \n",
    "    mlflow.log_metric(\"numeric_features_count\", len(numeric_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df, is_train=True):\n",
    "    \"\"\"\n",
    "    Data cleaning function\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Remove outliers (only for training data)\n",
    "    if is_train:\n",
    "        # Remove extreme outliers based on GrLivArea and SalePrice\n",
    "        df_clean = df_clean.drop(df_clean[(df_clean['GrLivArea'] > 4000) & \n",
    "                                         (df_clean['SalePrice'] < 300000)].index)\n",
    "    \n",
    "    # Handle missing values for specific features\n",
    "    # Categorical features with meaningful NA\n",
    "    categorical_na_features = ['Alley', 'BsmtQual', 'BsmtCond', 'BsmtExposure', \n",
    "                              'BsmtFinType1', 'BsmtFinType2', 'FireplaceQu',\n",
    "                              'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
    "                              'PoolQC', 'Fence', 'MiscFeature']\n",
    "    \n",
    "    for feature in categorical_na_features:\n",
    "        if feature in df_clean.columns:\n",
    "            df_clean[feature] = df_clean[feature].fillna('None')\n",
    "    \n",
    "    # Numerical features with meaningful zero\n",
    "    numerical_zero_features = ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n",
    "                              'BsmtFullBath', 'BsmtHalfBath', 'GarageYrBlt',\n",
    "                              'GarageArea', 'GarageCars', 'MasVnrArea']\n",
    "    \n",
    "    for feature in numerical_zero_features:\n",
    "        if feature in df_clean.columns:\n",
    "            df_clean[feature] = df_clean[feature].fillna(0)\n",
    "    \n",
    "    # Other categorical features - fill with mode\n",
    "    categorical_features = df_clean.select_dtypes(include=['object']).columns\n",
    "    for feature in categorical_features:\n",
    "        if df_clean[feature].isnull().any():\n",
    "            mode_value = df_clean[feature].mode()[0] if len(df_clean[feature].mode()) > 0 else 'Unknown'\n",
    "            df_clean[feature] = df_clean[feature].fillna(mode_value)\n",
    "    \n",
    "    # Numerical features - fill with median\n",
    "    numerical_features = df_clean.select_dtypes(include=[np.number]).columns\n",
    "    for feature in numerical_features:\n",
    "        if df_clean[feature].isnull().any():\n",
    "            median_value = df_clean[feature].median()\n",
    "            df_clean[feature] = df_clean[feature].fillna(median_value)\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning\n",
    "with mlflow.start_run(run_name=\"Data_Cleaning\"):\n",
    "    train_clean = clean_data(train_data, is_train=True)\n",
    "    test_clean = clean_data(test_data, is_train=False)\n",
    "    \n",
    "    print(f\"Original training data shape: {train_data.shape}\")\n",
    "    print(f\"Cleaned training data shape: {train_clean.shape}\")\n",
    "    \n",
    "    # Log cleaning results\n",
    "    mlflow.log_param(\"original_train_shape\", train_data.shape)\n",
    "    mlflow.log_param(\"cleaned_train_shape\", train_clean.shape)\n",
    "    mlflow.log_param(\"outliers_removed\", train_data.shape[0] - train_clean.shape[0])\n",
    "    \n",
    "    # Check remaining missing values\n",
    "    missing_after = train_clean.isnull().sum().sum()\n",
    "    print(f\"Missing values after cleaning: {missing_after}\")\n",
    "    mlflow.log_metric(\"missing_values_after_cleaning\", missing_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    \"\"\"\n",
    "    Create new features and transform existing ones\n",
    "    \"\"\"\n",
    "    df_fe = df.copy()\n",
    "    \n",
    "    # Create new features\n",
    "    df_fe['TotalSF'] = df_fe['TotalBsmtSF'] + df_fe['1stFlrSF'] + df_fe['2ndFlrSF']\n",
    "    df_fe['Total_Bathrooms'] = (df_fe['FullBath'] + (0.5 * df_fe['HalfBath']) +\n",
    "                               df_fe['BsmtFullBath'] + (0.5 * df_fe['BsmtHalfBath']))\n",
    "    df_fe['Total_porch_sf'] = (df_fe['OpenPorchSF'] + df_fe['3SsnPorch'] +\n",
    "                              df_fe['EnclosedPorch'] + df_fe['ScreenPorch'] +\n",
    "                              df_fe['WoodDeckSF'])\n",
    "    \n",
    "    # Age of house\n",
    "    df_fe['HouseAge'] = df_fe['YrSold'] - df_fe['YearBuilt']\n",
    "    df_fe['RemodAge'] = df_fe['YrSold'] - df_fe['YearRemodAdd']\n",
    "    \n",
    "    # Garage age\n",
    "    df_fe['GarageAge'] = df_fe['YrSold'] - df_fe['GarageYrBlt']\n",
    "    df_fe['GarageAge'] = df_fe['GarageAge'].fillna(0)\n",
    "    \n",
    "    # Has features\n",
    "    df_fe['HasBasement'] = (df_fe['TotalBsmtSF'] > 0).astype(int)\n",
    "    df_fe['HasGarage'] = (df_fe['GarageArea'] > 0).astype(int)\n",
    "    df_fe['HasFireplace'] = (df_fe['Fireplaces'] > 0).astype(int)\n",
    "    df_fe['HasPool'] = (df_fe['PoolArea'] > 0).astype(int)\n",
    "    \n",
    "    # Price per square foot proxies\n",
    "    df_fe['Price_per_sqft_total'] = df_fe['TotalSF']\n",
    "    df_fe['Price_per_sqft_living'] = df_fe['GrLivArea']\n",
    "    \n",
    "    return df_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature engineering\n",
    "with mlflow.start_run(run_name=\"Feature_Engineering\"):\n",
    "    train_fe = feature_engineering(train_clean)\n",
    "    test_fe = feature_engineering(test_clean)\n",
    "    \n",
    "    print(f\"Shape after feature engineering: {train_fe.shape}\")\n",
    "    \n",
    "    # Log feature engineering results\n",
    "    mlflow.log_param(\"features_after_engineering\", train_fe.shape[1])\n",
    "    mlflow.log_param(\"new_features_created\", train_fe.shape[1] - train_clean.shape[1])\n",
    "    \n",
    "    # Show new features\n",
    "    new_features = set(train_fe.columns) - set(train_clean.columns)\n",
    "    print(f\"New features created: {new_features}\")\n",
    "    mlflow.log_param(\"new_features_list\", list(new_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_features(train_df, test_df, target_col='SalePrice'):\n",
    "    \"\"\"\n",
    "    Encode categorical features\n",
    "    \"\"\"\n",
    "    # Separate features and target\n",
    "    if target_col in train_df.columns:\n",
    "        X_train = train_df.drop(columns=[target_col])\n",
    "        y_train = train_df[target_col]\n",
    "    else:\n",
    "        X_train = train_df.copy()\n",
    "        y_train = None\n",
    "    \n",
    "    X_test = test_df.copy()\n",
    "    \n",
    "    # Get categorical and numerical features\n",
    "    categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "    numerical_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    # Remove ID column if present\n",
    "    if 'Id' in numerical_features:\n",
    "        numerical_features.remove('Id')\n",
    "        X_train = X_train.drop('Id', axis=1)\n",
    "        X_test = X_test.drop('Id', axis=1)\n",
    "    \n",
    "    # One-hot encoding for categorical features\n",
    "    X_train_encoded = pd.get_dummies(X_train, columns=categorical_features, drop_first=True)\n",
    "    X_test_encoded = pd.get_dummies(X_test, columns=categorical_features, drop_first=True)\n",
    "    \n",
    "    # Align columns between train and test\n",
    "    missing_cols_test = set(X_train_encoded.columns) - set(X_test_encoded.columns)\n",
    "    missing_cols_train = set(X_test_encoded.columns) - set(X_train_encoded.columns)\n",
    "    \n",
    "    # Add missing columns to test set\n",
    "    for col in missing_cols_test:\n",
    "        X_test_encoded[col] = 0\n",
    "    \n",
    "    # Add missing columns to train set\n",
    "    for col in missing_cols_train:\n",
    "        X_train_encoded[col] = 0\n",
    "    \n",
    "    # Reorder columns\n",
    "    X_test_encoded = X_test_encoded[X_train_encoded.columns]\n",
    "    \n",
    "    return X_train_encoded, X_test_encoded, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply encoding\n",
    "with mlflow.start_run(run_name=\"Feature_Encoding\"):\n",
    "    X_train_encoded, X_test_encoded, y_train = encode_features(train_fe, test_fe)\n",
    "    \n",
    "    print(f\"Encoded training features shape: {X_train_encoded.shape}\")\n",
    "    print(f\"Encoded test features shape: {X_test_encoded.shape}\")\n",
    "    \n",
    "    mlflow.log_param(\"encoded_features_count\", X_train_encoded.shape[1])\n",
    "    mlflow.log_param(\"train_samples\", X_train_encoded.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_feature_selection(X_train, y_train, method='all'):\n",
    "    \"\"\"\n",
    "    Perform feature selection using different methods\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    if method == 'univariate' or method == 'all':\n",
    "        # Univariate feature selection\n",
    "        selector_univariate = SelectKBest(score_func=f_regression, k=50)\n",
    "        X_train_univariate = selector_univariate.fit_transform(X_train, y_train)\n",
    "        selected_features_univariate = X_train.columns[selector_univariate.get_support()].tolist()\n",
    "        results['univariate'] = {\n",
    "            'selector': selector_univariate,\n",
    "            'features': selected_features_univariate,\n",
    "            'X_transformed': X_train_univariate\n",
    "        }\n",
    "    \n",
    "    if method == 'rfe' or method == 'all':\n",
    "        # Recursive Feature Elimination\n",
    "        estimator = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "        selector_rfe = RFE(estimator, n_features_to_select=50)\n",
    "        X_train_rfe = selector_rfe.fit_transform(X_train, y_train)\n",
    "        selected_features_rfe = X_train.columns[selector_rfe.get_support()].tolist()\n",
    "        results['rfe'] = {\n",
    "            'selector': selector_rfe,\n",
    "            'features': selected_features_rfe,\n",
    "            'X_transformed': X_train_rfe\n",
    "        }\n",
    "    \n",
    "    if method == 'lasso' or method == 'all':\n",
    "        # L1-based feature selection\n",
    "        lasso = Lasso(alpha=0.01, random_state=42)\n",
    "        selector_lasso = SelectFromModel(lasso)\n",
    "        X_train_lasso = selector_lasso.fit_transform(X_train, y_train)\n",
    "        selected_features_lasso = X_train.columns[selector_lasso.get_support()].tolist()\n",
    "        results['lasso'] = {\n",
    "            'selector': selector_lasso,\n",
    "            'features': selected_features_lasso,\n",
    "            'X_transformed': X_train_lasso\n",
    "        }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform feature selection experiments\n",
    "feature_selection_methods = ['univariate', 'rfe', 'lasso']\n",
    "selection_results = {}\n",
    "\n",
    "for method in feature_selection_methods:\n",
    "    with mlflow.start_run(run_name=f\"Feature_Selection_{method}\"):\n",
    "        result = perform_feature_selection(X_train_encoded, y_train, method=method)\n",
    "        selection_results[method] = result[method]\n",
    "        \n",
    "        print(f\"\\n{method.upper()} Feature Selection:\")\n",
    "        print(f\"Selected {len(result[method]['features'])} features\")\n",
    "        \n",
    "        mlflow.log_param(\"selection_method\", method)\n",
    "        mlflow.log_param(\"selected_features_count\", len(result[method]['features']))\n",
    "        mlflow.log_param(\"original_features_count\", X_train_encoded.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, y_train, cv=5):\n",
    "    \"\"\"\n",
    "    Evaluate model using cross-validation\n",
    "    \"\"\"\n",
    "    # Cross-validation scores\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=cv, \n",
    "                               scoring='neg_mean_squared_error')\n",
    "    rmse_scores = np.sqrt(-cv_scores)\n",
    "    \n",
    "    # Train on full training set for additional metrics\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_train)\n",
    "    \n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "    train_r2 = r2_score(y_train, y_pred)\n",
    "    train_mae = mean_absolute_error(y_train, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'cv_rmse_mean': rmse_scores.mean(),\n",
    "        'cv_rmse_std': rmse_scores.std(),\n",
    "        'train_rmse': train_rmse,\n",
    "        'train_r2': train_r2,\n",
    "        'train_mae': train_mae,\n",
    "        'fitted_model': model\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to test\n",
    "models = {\n",
    "    'Linear_Regression': LinearRegression(),\n",
    "    'Ridge': Ridge(alpha=1.0),\n",
    "    'Lasso': Lasso(alpha=0.01),\n",
    "    'ElasticNet': ElasticNet(alpha=0.01),\n",
    "    'Random_Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'XGBoost': xgb.XGBRegressor(n_estimators=100, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test models with different feature selection methods\n",
    "best_model_info = {'score': float('inf'), 'model': None, 'features': None, 'method': None}\n",
    "\n",
    "for selection_method in ['univariate', 'rfe', 'lasso']:\n",
    "    X_selected = selection_results[selection_method]['X_transformed']\n",
    "    selected_features = selection_results[selection_method]['features']\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        with mlflow.start_run(run_name=f\"{model_name}_{selection_method}\"):\n",
    "            try:\n",
    "                # Evaluate model\n",
    "                results = evaluate_model(model, X_selected, y_train)\n",
    "                \n",
    "                # Log parameters\n",
    "                mlflow.log_param(\"model_type\", model_name)\n",
    "                mlflow.log_param(\"feature_selection\", selection_method)\n",
    "                mlflow.log_param(\"n_features\", len(selected_features))\n",
    "                \n",
    "                # Log metrics\n",
    "                mlflow.log_metric(\"cv_rmse_mean\", results['cv_rmse_mean'])\n",
    "                mlflow.log_metric(\"cv_rmse_std\", results['cv_rmse_std'])\n",
    "                mlflow.log_metric(\"train_rmse\", results['train_rmse'])\n",
    "                mlflow.log_metric(\"train_r2\", results['train_r2'])\n",
    "                mlflow.log_metric(\"train_mae\", results['train_mae'])\n",
    "                \n",
    "                # Log model\n",
    "                mlflow.sklearn.log_model(results['fitted_model'], f\"model_{model_name}\")\n",
    "                \n",
    "                print(f\"{model_name} with {selection_method}: CV RMSE = {results['cv_rmse_mean']:.4f} (+/- {results['cv_rmse_std']:.4f})\")\n",
    "                \n",
    "                # Track best model\n",
    "                if results['cv_rmse_mean'] < best_model_info['score']:\n",
    "                    best_model_info = {\n",
    "                        'score': results['cv_rmse_mean'],\n",
    "                        'model': results['fitted_model'],\n",
    "                        'features': selected_features,\n",
    "                        'method': selection_method,\n",
    "                        'model_name': model_name\n",
    "                    }\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error with {model_name} and {selection_method}: {e}\")\n",
    "\n",
    "print(f\"\\nBest model: {best_model_info['model_name']} with {best_model_info['method']} selection\")\n",
    "print(f\"Best CV RMSE: {best_model_info['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for the best model type\n",
    "if 'Random_Forest' in best_model_info['model_name']:\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    base_model = RandomForestRegressor(random_state=42)\n",
    "elif 'XGBoost' in best_model_info['model_name']:\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.8, 0.9, 1.0]\n",
    "    }\n",
    "    base_model = xgb.XGBRegressor(random_state=42)\n",
    "else:\n",
    "    param_grid = {'alpha': [0.001, 0.01, 0.1, 1.0, 10.0]}\n",
    "    if 'Ridge' in best_model_info['model_name']:\n",
    "        base_model = Ridge()\n",
    "    else:\n",
    "        base_model = Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the features for the best selection method\n",
    "best_selector = selection_results[best_model_info['method']]['selector']\n",
    "X_train_best = best_selector.transform(X_train_encoded)\n",
    "\n",
    "with mlflow.start_run(run_name=\"Hyperparameter_Optimization\"):\n",
    "    # Grid search\n",
    "    grid_search = GridSearchCV(\n",
    "        base_model, \n",
    "        param_grid, \n",
    "        cv=5, \n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train_best, y_train)\n",
    "    \n",
    "    # Log best parameters and score\n",
    "    mlflow.log_params(grid_search.best_params_)\n",
    "    mlflow.log_metric(\"best_cv_rmse\", np.sqrt(-grid_search.best_score_))\n",
    "    \n",
    "    # Log the best model\n",
    "    mlflow.sklearn.log_model(grid_search.best_estimator_, \"best_model\")\n",
    "    \n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best CV RMSE: {np.sqrt(-grid_search.best_score_):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Final Model Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the best model\n",
    "with mlflow.start_run(run_name=\"Final_Model_Registration\"):\n",
    "    # Final model training and evaluation\n",
    "    final_model = grid_search.best_estimator_\n",
    "    final_model.fit(X_train_best, y_train)\n",
    "    \n",
    "    # Final predictions and metrics\n",
    "    y_pred_final = final_model.predict(X_train_best)\n",
    "    final_rmse = np.sqrt(mean_squared_error(y_train, y_pred_final))\n",
    "    final_r2 = r2_score(y_train, y_pred_final)\n",
    "    final_mae = mean_absolute_error(y_train, y_pred_final)\n",
    "    \n",
    "    # Log final metrics\n",
    "    mlflow.log_metric(\"final_rmse\", final_rmse)\n",
    "    mlflow.log_metric(\"final_r2\", final_r2)\n",
    "    mlflow.log_metric(\"final_mae\", final_mae)\n",
    "    mlflow.log_param(\"final_model_type\", best_model_info['model_name'])\n",
    "    mlflow.log_param(\"final_feature_selection\", best_model_info['method'])\n",
    "    \n",
    "    # Log model for registration\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        final_model, \n",
    "        \"final_model\",\n",
    "        registered_model_name=\"house_prices_final_model\"\n",
    "    )\n",
    "    \n",
    "    print(f\"Final model registered with RMSE: {final_rmse:.4f}\")\n",
    "    print(f\"Model URI: {model_info.model_uri}\")"
   ]
  },
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
